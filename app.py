from flask import Flask, Response, request
from flask_socketio import SocketIO
import cv2
import time
import numpy as np
from collections import defaultdict
from ultralytics import YOLO
import os
import time
import eventlet

eventlet.monkey_patch()  # Patch c√°c th∆∞ vi·ªán chu·∫©n ƒë·ªÉ ho·∫°t ƒë·ªông v·ªõi eventlet
from utils import check_in_out, is_landing, to_background_coords, warp_point
from flask import send_from_directory
import os

output_video_dir = "output_videos"
output_image_dir = "out_images"
output_time_file = "time_log.txt"
video_path = (
    "videos/Pickleball Th·ªß ƒê√¥ TV Live Stream - Pickleball Th·ªß ƒê√¥ TV (720p, h264).mp4"
)
out_video_path = os.path.join(output_video_dir, "full_video_output.mp4")
os.makedirs(output_video_dir, exist_ok=True)
os.makedirs(output_image_dir, exist_ok=True)
app = Flask(__name__)
# C·∫•u h√¨nh SocketIO v·ªõi async_mode=eventlet ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu k·∫øt n·ªëi
socketio = SocketIO(app, cors_allowed_origins="*", async_mode="eventlet")
start_tracking = False

# T·∫°o mutex ƒë·ªÉ ƒë·ªìng b·ªô h√≥a truy c·∫≠p
video_lock = eventlet.semaphore.Semaphore()
# M·ªü video m·ªôt l·∫ßn v√† ƒë√≥ng khi ·ª©ng d·ª•ng t·∫Øt
cap = cv2.VideoCapture(video_path)

model = YOLO("models/best_ball.pt")
track_history = defaultdict(lambda: [])

# Kh·ªüi t·∫°o th√¥ng s·ªë video
fps = cap.get(cv2.CAP_PROP_FPS)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# VideoWriter s·∫Ω ƒë∆∞·ª£c kh·ªüi t·∫°o khi c·∫ßn thi·∫øt
out = None

src_pts = None
dst_pts = np.float32([[0, 0], [300, 0], [300, 600], [0, 600]])
H = None
show_tracking = False

san_x = 300
san_y = 600


# V·∫Ω h√¨nh s√¢n b√≥ng t·ª´ 4 ƒëi·ªÉm g√≥c tr√™n frame
def draw_field(frame, src_pts):
    pts = src_pts.astype(np.int32).reshape((-1, 1, 2))  # Chuy·ªÉn sang ƒë·ªãnh d·∫°ng ph√π h·ª£p
    cv2.polylines(frame, [pts], isClosed=True, color=(0, 255, 0), thickness=2)


@app.route("/output_videos/<filename>")
def download_video(filename):
    return send_from_directory("output_videos", filename)


@app.route("/out_images/<filename>")
def download_image(filename):
    return send_from_directory("out_images", filename)


@socketio.on("corner_points")
def handle_corners(data):
    global src_pts
    global H

    corner_points = data["points"]  # [{x:..., y:...}, ...]
    print("‚úÖ Received corner points:", corner_points)

    # Chuy·ªÉn th√†nh NumPy array ki·ªÉu float32 v·ªõi shape (4, 2)
    src_pts = np.array([[p["x"], p["y"]] for p in corner_points], dtype=np.float32)

    # Ki·ªÉm tra s·ªë l∆∞·ª£ng ƒëi·ªÉm
    if src_pts.shape != (4, 2):
        print("‚ùå L·ªói: c·∫ßn ƒë√∫ng 4 ƒëi·ªÉm c√≥ d·∫°ng (x, y)")
        return

    # T√≠nh ma tr·∫≠n bi·∫øn ƒë·ªïi
    H = cv2.getPerspectiveTransform(src_pts, dst_pts)
    print("‚úÖ Ma tr·∫≠n bi·∫øn ƒë·ªïi H:", H)


@socketio.on("start_tracking")
def handle_start():
    global start_tracking, out
    start_tracking = True

    # Kh·ªüi t·∫°o VideoWriter ch·ªâ khi b·∫Øt ƒë·∫ßu tracking
    if out is None:
        with video_lock:
            fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # S·ª≠ d·ª•ng codec ƒë∆°n gi·∫£n h∆°n
            out = cv2.VideoWriter(
                out_video_path, fourcc, fps, (frame_width, frame_height)
            )

    print("Start tracking!")


@socketio.on("get_size")
def get_size():
    try:
        # S·ª≠ d·ª•ng video_lock ƒë·ªÉ tr√°nh xung ƒë·ªôt
        with video_lock:
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(width, height)
        socketio.emit("video_size", {"width": width, "height": height})
    except Exception as e:
        print(f"L·ªói khi l·∫•y k√≠ch th∆∞·ªõc video: {e}")


@socketio.on("connect")
def handle_connect():
    print(f"Client connected: {request.sid}")


@socketio.on("disconnect")
def handle_disconnect():
    print(f"Client disconnected: {request.sid}")


@socketio.on("stop_tracking")
def handle_stop():
    global start_tracking, out
    start_tracking = False
    with video_lock:
        if out is not None:
            out.release()
            print("Stopped video recording.")
            out = None  # ƒê·∫∑t l·∫°i ƒë·ªÉ khi b·∫Øt ƒë·∫ßu l·∫°i s·∫Ω t·∫°o m·ªõi

    socketio.emit(
        "stop_tracking",
        {
            "video": "output_videos/full_video_output.mp4",
            "time_log": "time_log.txt",
        },
    )


@socketio.on("show_tracking")
def handle_show_tracking():
    global show_tracking
    show_tracking = True


last_positions = []

from datetime import datetime


def generate_frames():
    global start_tracking, dst_pts, out, show_tracking
    with open(output_time_file, "w") as time_file:
        while True:
            with video_lock:  # Kh√≥a ƒë·ªÉ tr√°nh xung ƒë·ªôt truy c·∫≠p
                success, frame = cap.read()

            if not success:
                break

            # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh xung ƒë·ªôt
            current_frame = frame.copy()

            # Ghi frame v√†o video ƒë·∫ßu ra n·∫øu ƒëang tracking
            if start_tracking and out is not None:
                try:
                    with video_lock:
                        out.write(frame)
                except Exception as e:
                    print(f"L·ªói khi ghi video: {e}")

            # Trong v√≤ng l·∫∑p x·ª≠ l√Ω ·∫£nh ho·∫∑c trong h√†m x·ª≠ l√Ω khung h√¨nh:
            if src_pts is not None:
                draw_field(current_frame, src_pts)

            # N·∫øu c√≥ ƒëi·ªÉm v√† ƒëang tracking
            if start_tracking and len(dst_pts) == 4:
                try:
                    result = model.track(
                        current_frame, persist=True, verbose=False, conf=0.3
                    )[0]
                    if result.boxes and result.boxes.id is not None:
                        boxes = result.boxes.xywh.cpu()
                        track_ids = [1 for _ in boxes]

                        for box, track_id in zip(boxes, track_ids):
                            x, y, w, h = box
                            track = track_history[track_id]
                            track.append((float(x), float(y)))
                            if len(track) > 30:
                                track.pop(0)
                            if show_tracking:
                                points = (
                                    np.hstack(track)
                                    .astype(np.int32)
                                    .reshape((-1, 1, 2))
                                )
                                cv2.polylines(
                                    current_frame,
                                    [points],
                                    isClosed=False,
                                    color=(230, 230, 230),
                                    thickness=2,
                                )
                        for track_id, track in track_history.items():
                            if len(track) >= 3:
                                for i in range(1, len(track) - 1):
                                    if is_landing(track, i):
                                        landing_pt = track[i]
                                        court_pt = warp_point(landing_pt, H)
                                        status = check_in_out(court_pt)
                                        cx, cy = map(int, court_pt)
                                        if (cx, cy) not in last_positions:
                                            # C·∫≠p nh·∫≠t danh s√°ch v·ªã tr√≠
                                            last_positions.append((cx, cy))
                                            if len(last_positions) > 30:
                                                last_positions.pop(
                                                    0
                                                )  # Gi·ªØ l·∫°i 30 v·ªã tr√≠ g·∫ßn nh·∫•t

                                            # Ghi file
                                            timestamp = time.strftime(
                                                "%H:%M:%S",
                                                time.gmtime(
                                                    cap.get(cv2.CAP_PROP_POS_MSEC)
                                                    / 1000
                                                ),
                                            )
                                            new_cx, new_cy = to_background_coords(cx,cy)
                                            time_file.write(
                                                f"{status};{timestamp};{new_cx};{new_cy}\n"
                                            )

                                            # Emit v·ªÅ client
                                            timestamp = time.strftime("%H:%M:%S")

                                            timestamp_name = datetime.now().strftime(
                                                "%Y%m%d_%H%M%S_%f"
                                            )
                                            filename = f"out_images/{status}_{timestamp_name}.png"
                                            cv2.imwrite(filename, frame)
                                            socketio.emit(
                                                "ball_status",
                                                {
                                                    "status": status,
                                                    "timestamp": timestamp,
                                                    "image": timestamp + ".png",
                                                    "x": new_cx,
                                                    "y": new_cy,
                                                },
                                            )
                except Exception as e:
                    print(f"L·ªói khi x·ª≠ l√Ω tracking: {e}")

            # Encode v√† g·ª≠i khung h√¨nh
            ret, buffer = cv2.imencode(".jpg", current_frame)
            frame_bytes = buffer.tobytes()
            yield (
                b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
            )
            # Nh∆∞·ªùng lu·ªìng x·ª≠ l√Ω ƒë·ªÉ c√°c k·∫øt n·ªëi kh√°c c√≥ th·ªÉ ho·∫°t ƒë·ªông
            eventlet.sleep(0.03)


@app.route("/video_feed")
def video_feed():
    return Response(
        generate_frames(), mimetype="multipart/x-mixed-replace; boundary=frame"
    )


import socket  # th√™m ·ªü ƒë·∫ßu file

if __name__ == "__main__":
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
        finally:
            s.close()

        print(f"üì° Server is running at: http://{local_ip}:5000")
        print("üöÄ Starting server on port 5000...")

        socketio.run(app, host="0.0.0.0", port=5000)
    finally:
        if out is not None:
            with video_lock:
                out.release()
        if cap.isOpened():
            with video_lock:
                cap.release()
